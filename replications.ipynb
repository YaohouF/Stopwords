{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "17a67225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Almost perfect</td>\n",
       "      <td>...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This could be a great app if it was predictabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>this could be great app if was predictable, bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>thi could be a gre ap if it was predictable, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take a photo of your boarding pass</td>\n",
       "      <td>...</td>\n",
       "      <td>could great app predictable, full bugs unpredi...</td>\n",
       "      <td>9</td>\n",
       "      <td>AppStore_Random</td>\n",
       "      <td>382698565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>this could be great app if be predictable, but...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I can't open since the last 2 updates Pop-ups ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>can't open since last 2 updates pop-ups go cra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>i can't op sint the last 2 upd pop-ups go craz...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Won't open due to pop-ups since upgrade</td>\n",
       "      <td>...</td>\n",
       "      <td>can't open since last 2 updates pop-ups go cra...</td>\n",
       "      <td>1</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>can't open since last 2 update pop-up go crazy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Use to love this app but it's not working afte...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>use to love this app but its not working after...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>us to lov thi ap but its not work aft new upda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Working After Update</td>\n",
       "      <td>...</td>\n",
       "      <td>use love app its working new update pages wont...</td>\n",
       "      <td>4</td>\n",
       "      <td>AppStore_Random</td>\n",
       "      <td>404299862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>use to love this app but its not work after ne...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Urrrrm\\tAfter my third re installing, it final...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>urrrrm after third re installing, finally has ...</td>\n",
       "      <td>cid-gp:AOqpTOE3YjNzLOttARdiYx3b2O02-B1k-FO01WO...</td>\n",
       "      <td>13</td>\n",
       "      <td>urrrrm aft my third re installing, it fin has ...</td>\n",
       "      <td>paid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>urrrrm third re installing, finally scenery ha...</td>\n",
       "      <td>14</td>\n",
       "      <td>PlayStore_Random</td>\n",
       "      <td>#3_Need for Speed Most Wanted</td>\n",
       "      <td>12:44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>urrrrm after third re installing, finally have...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>3687</td>\n",
       "      <td>Loved this app from jump!\\tHave never had any ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>loved this app from jump! have never had any i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>733</td>\n",
       "      <td>lov thi ap from jump! hav nev had any issu wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>loved app jump! never issues app, go enhancing...</td>\n",
       "      <td>4</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>love this app from jump! have never have any i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>3688</td>\n",
       "      <td>Best app\\tCan always edit my pics and they wil...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>best app can always edit pics will end well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>734</td>\n",
       "      <td>best ap can alway edit my pic and they wil end...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>best app always edit pics end well</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>best app can always edit pic will end well</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>3689</td>\n",
       "      <td>Awesome\\tpics art is my only app for editing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>awesome pics art only app for editing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>735</td>\n",
       "      <td>awesom pic art is my on ap for edit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>awesome pics art app editing</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>awesome pic art only app for edit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>3690</td>\n",
       "      <td>5star!!!!!\\tI love it! ! Sumtime hate it catch...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5star!!!!! love it! ! sumtime hate catch editi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736</td>\n",
       "      <td>5star!!!!! i lov it! ! sumtim hat it catch mys...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5star!!!!! love it! ! sumtime hate catch editi...</td>\n",
       "      <td>3</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5star!!!!! love it! ! sumtime hate catch edit ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>3691</td>\n",
       "      <td>Favourite hands down for photo editing ?\\tEasy...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>favourite hands for photo editing ? easy to us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>737</td>\n",
       "      <td>favourit hand down for photo edit ? easy to us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>favourite hands photo editing ? easy use smart...</td>\n",
       "      <td>1</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>favourite hand for photo edit ? easy to use sm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3691 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_num                                             review  rating  past  \\\n",
       "0          1  Besides the occasional crash, this is an amazi...       5     0   \n",
       "1          2  This could be a great app if it was predictabl...       1     1   \n",
       "2          3  I can't open since the last 2 updates Pop-ups ...       1     0   \n",
       "3          4  Use to love this app but it's not working afte...       1     1   \n",
       "4          5  Urrrrm\\tAfter my third re installing, it final...       3     5   \n",
       "...      ...                                                ...     ...   ...   \n",
       "3686    3687  Loved this app from jump!\\tHave never had any ...       5     3   \n",
       "3687    3688  Best app\\tCan always edit my pics and they wil...       5     0   \n",
       "3688    3689       Awesome\\tpics art is my only app for editing       3     0   \n",
       "3689    3690  5star!!!!!\\tI love it! ! Sumtime hate it catch...       5     0   \n",
       "3690    3691  Favourite hands down for photo editing ?\\tEasy...       5     0   \n",
       "\n",
       "                                      stopwords_removal  \\\n",
       "0     besides occasional crash, this amazing product...   \n",
       "1     this could be great app if was predictable, bu...   \n",
       "2     can't open since last 2 updates pop-ups go cra...   \n",
       "3     use to love this app but its not working after...   \n",
       "4     urrrrm after third re installing, finally has ...   \n",
       "...                                                 ...   \n",
       "3686  loved this app from jump! have never had any i...   \n",
       "3687        best app can always edit pics will end well   \n",
       "3688              awesome pics art only app for editing   \n",
       "3689  5star!!!!! love it! ! sumtime hate catch editi...   \n",
       "3690  favourite hands for photo editing ? easy to us...   \n",
       "\n",
       "                                               reviewer   id  \\\n",
       "0                                                   NaN  264   \n",
       "1                                                   NaN  111   \n",
       "2                                                   NaN  210   \n",
       "3                                                   NaN   53   \n",
       "4     cid-gp:AOqpTOE3YjNzLOttARdiYx3b2O02-B1k-FO01WO...   13   \n",
       "...                                                 ...  ...   \n",
       "3686                                                NaN  733   \n",
       "3687                                                NaN  734   \n",
       "3688                                                NaN  735   \n",
       "3689                                                NaN  736   \n",
       "3690                                                NaN  737   \n",
       "\n",
       "                                                stemmed   fee  \\\n",
       "0     besid the occa crash, thi is an amaz produc wi...   NaN   \n",
       "1     thi could be a gre ap if it was predictable, b...   NaN   \n",
       "2     i can't op sint the last 2 upd pop-ups go craz...   NaN   \n",
       "3     us to lov thi ap but its not work aft new upda...   NaN   \n",
       "4     urrrrm aft my third re installing, it fin has ...  paid   \n",
       "...                                                 ...   ...   \n",
       "3686  lov thi ap from jump! hav nev had any issu wit...   NaN   \n",
       "3687  best ap can alway edit my pic and they wil end...   NaN   \n",
       "3688                awesom pic art is my on ap for edit   NaN   \n",
       "3689  5star!!!!! i lov it! ! sumtim hat it catch mys...   NaN   \n",
       "3690  favourit hand down for photo edit ? easy to us...   NaN   \n",
       "\n",
       "                                        title  ...  \\\n",
       "0                              Almost perfect  ...   \n",
       "1          Take a photo of your boarding pass  ...   \n",
       "2     Won't open due to pop-ups since upgrade  ...   \n",
       "3                    Not Working After Update  ...   \n",
       "4                                         NaN  ...   \n",
       "...                                       ...  ...   \n",
       "3686                                      NaN  ...   \n",
       "3687                                      NaN  ...   \n",
       "3688                                      NaN  ...   \n",
       "3689                                      NaN  ...   \n",
       "3690                                      NaN  ...   \n",
       "\n",
       "                                 stopwords_removal_nltk  present_simple  \\\n",
       "0     besides occasional crash, amazing product tons...               2   \n",
       "1     could great app predictable, full bugs unpredi...               9   \n",
       "2     can't open since last 2 updates pop-ups go cra...               1   \n",
       "3     use love app its working new update pages wont...               4   \n",
       "4     urrrrm third re installing, finally scenery ha...              14   \n",
       "...                                                 ...             ...   \n",
       "3686  loved app jump! never issues app, go enhancing...               4   \n",
       "3687                 best app always edit pics end well               2   \n",
       "3688                       awesome pics art app editing               2   \n",
       "3689  5star!!!!! love it! ! sumtime hate catch editi...               3   \n",
       "3690  favourite hands photo editing ? easy use smart...               1   \n",
       "\n",
       "                          dataSource                          appId   date  \\\n",
       "0     RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "1                    AppStore_Random                      382698565    NaN   \n",
       "2     RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "3                    AppStore_Random                      404299862    NaN   \n",
       "4                   PlayStore_Random  #3_Need for Speed Most Wanted  12:44   \n",
       "...                              ...                            ...    ...   \n",
       "3686  RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "3687  RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "3688  RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "3689  RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "3690  RE2014_app_and_play_store_apps                            NaN    NaN   \n",
       "\n",
       "      sentiScore_pos present_con  length_words  \\\n",
       "0                  3           1            22   \n",
       "1                  3           0            58   \n",
       "2                  2           1            24   \n",
       "3                  3           1            39   \n",
       "4                  4           2           150   \n",
       "...              ...         ...           ...   \n",
       "3686               4           0            37   \n",
       "3687               2           0            13   \n",
       "3688               3           0             9   \n",
       "3689               3           1            35   \n",
       "3690               2           1            16   \n",
       "\n",
       "                        stopwords_removal_lemmatization Exclude  \n",
       "0     besides occasional crash, this amaze product w...     NaN  \n",
       "1     this could be great app if be predictable, but...     NaN  \n",
       "2     can't open since last 2 update pop-up go crazy...     NaN  \n",
       "3     use to love this app but its not work after ne...     NaN  \n",
       "4     urrrrm after third re installing, finally have...     NaN  \n",
       "...                                                 ...     ...  \n",
       "3686  love this app from jump! have never have any i...     NaN  \n",
       "3687         best app can always edit pic will end well     NaN  \n",
       "3688                  awesome pic art only app for edit     NaN  \n",
       "3689  5star!!!!! love it! ! sumtime hate catch edit ...     NaN  \n",
       "3690  favourite hand for photo edit ? easy to use sm...     NaN  \n",
       "\n",
       "[3691 rows x 26 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "full_data = pd.read_csv(\"Maalej_Dataset.csv\")\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "db43f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = full_data[['id_num', 'review','stopwords_removal','stopwords_removal_lemmatization', \"lemmatized_comment\"]]\n",
    "numerical_data = full_data[['rating','past','present_simple','present_con','future','sentiScore_pos',\"sentiScore_neg\"]]\n",
    "label = full_data[['task']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8398a1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237ac2e",
   "metadata": {},
   "source": [
    "Replicate the best model (BOW - stopwords + lemmatization + tense + rating + 2*senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0c0cc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training predictors\n",
    "text=text_data.review.values.astype('U')\n",
    "vect_11 = CountVectorizer(ngram_range=(2, 2))\n",
    "BOW_feature = pd.DataFrame(vect_11.fit_transform(text).toarray())\n",
    "Y = full_data.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c8b1284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31174</th>\n",
       "      <th>31175</th>\n",
       "      <th>31176</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "      <th>future</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3691 rows × 31184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  31174  31175  31176  rating  past  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     5   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...     ...   ...   \n",
       "3686  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     3   \n",
       "3687  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3688  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     0   \n",
       "3689  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3690  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "\n",
       "      present_simple  present_con  future  sentiScore_pos  sentiScore_neg  \n",
       "0                  2            1       0               3              -1  \n",
       "1                  9            0       0               3              -1  \n",
       "2                  1            1       0               2              -1  \n",
       "3                  4            1       0               3              -1  \n",
       "4                 14            2       0               4              -4  \n",
       "...              ...          ...     ...             ...             ...  \n",
       "3686               4            0       0               4              -1  \n",
       "3687               2            0       1               2              -1  \n",
       "3688               2            0       0               3              -1  \n",
       "3689               3            1       0               3              -4  \n",
       "3690               1            1       0               2              -1  \n",
       "\n",
       "[3691 rows x 31184 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW_feature\n",
    "frames = [BOW_feature,numerical_data]\n",
    "X = pd.concat(frames,axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c09c2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ''\n",
    "for i in range(len(text)):\n",
    "    a = a + text[i] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1c5f42dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9655"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9fb9dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "def get_performance(pred,label,target):\n",
    "    \n",
    "    print('Precision: %.3f' % precision_score(label, pred,average=\"binary\", pos_label=target))\n",
    "    print('Recall: %.3f' % recall_score(label, pred,average=\"binary\", pos_label=target))\n",
    "    print('F1: %.3f' % f1_score(label, pred,average=\"binary\", pos_label=target))\n",
    "    print('Accuracy: %.3f' % accuracy_score(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "416482d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0, train_size = .70)\n",
    "\n",
    "# Build the model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "54d7df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get predict value on the training dataset\n",
    "NB_predict_train = NB.predict(X_train)\n",
    "# Predict on test set\n",
    "NB_predict_test = NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "35e1fb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099109562524197"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,NB_predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "583071ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3212996389891697"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,NB_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59898c4",
   "metadata": {},
   "source": [
    "Multi_classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "51ebb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(label,target):\n",
    "    Y_target = label.copy()\n",
    "    for i in range(len(label)):\n",
    "        if label[i] != target:\n",
    "            Y_target[i] = \"other\"\n",
    "    return Y_target\n",
    "Y_PD = transform_label(Y,\"PD\")\n",
    "Y_RT = transform_label(Y,\"RT\")\n",
    "Y_FR = transform_label(Y,\"FR\")\n",
    "Y_UE = transform_label(Y,\"UE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b99648e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PD, X_test_PD, y_train_PD, y_test_PD = train_test_split(X, Y_PD, random_state=0, train_size = .70)\n",
    "\n",
    "# Build the model\n",
    "# Classifier for PD\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "NB_PD = GaussianNB()\n",
    "NB_PD.fit(X_train_PD,y_train_PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "27310b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.097\n",
      "Recall: 0.250\n",
      "F1: 0.139\n",
      "Accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "NB_predict_test_PD = NB_PD.predict(X_test_PD)\n",
    "get_performance(NB_predict_test_PD,y_test_PD,'PD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5ea89e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.744\n",
      "Recall: 0.716\n",
      "F1: 0.730\n",
      "Accuracy: 0.658\n"
     ]
    }
   ],
   "source": [
    "# Classifier for RT\n",
    "X_train_RT, X_test_RT, y_train_RT, y_test_RT = train_test_split(X, Y_RT, random_state=0, train_size = .70)\n",
    "NB_RT = GaussianNB()\n",
    "NB_RT.fit(X_train_RT,y_train_RT)\n",
    "NB_predict_test_RT = NB_RT.predict(X_test_RT)\n",
    "get_performance(NB_predict_test_RT,y_test_RT,'RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a324309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.045\n",
      "Recall: 0.131\n",
      "F1: 0.067\n",
      "Accuracy: 0.723\n"
     ]
    }
   ],
   "source": [
    "# Classifier for FR\n",
    "X_train_FR, X_test_FR, y_train_FR, y_test_FR = train_test_split(X, Y_FR, random_state=0, train_size = .70)\n",
    "NB_FR = GaussianNB()\n",
    "NB_FR.fit(X_train_FR,y_train_FR)\n",
    "NB_predict_test_FR = NB_FR.predict(X_test_FR)\n",
    "get_performance(NB_predict_test_FR,y_test_FR,'FR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6c46e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.079\n",
      "Recall: 0.173\n",
      "F1: 0.109\n",
      "Accuracy: 0.497\n"
     ]
    }
   ],
   "source": [
    "# Classifier for UE\n",
    "X_train_UE, X_test_UE, y_train_UE, y_test_UE = train_test_split(X, Y_UE, random_state=0, train_size = .70)\n",
    "NB_UE = GaussianNB()\n",
    "NB_UE.fit(X_train_UE,y_train_UE)\n",
    "NB_predict_test_UE = NB_UE.predict(X_test_UE)\n",
    "get_performance(NB_predict_test_UE,y_test_UE,'UE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb27295",
   "metadata": {},
   "source": [
    "Model without stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b93192ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29391</th>\n",
       "      <th>29392</th>\n",
       "      <th>29393</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "      <th>future</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3691 rows × 29401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  29391  29392  29393  rating  past  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     5   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...     ...   ...   \n",
       "3686  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     3   \n",
       "3687  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3688  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     0   \n",
       "3689  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3690  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "\n",
       "      present_simple  present_con  future  sentiScore_pos  sentiScore_neg  \n",
       "0                  2            1       0               3              -1  \n",
       "1                  9            0       0               3              -1  \n",
       "2                  1            1       0               2              -1  \n",
       "3                  4            1       0               3              -1  \n",
       "4                 14            2       0               4              -4  \n",
       "...              ...          ...     ...             ...             ...  \n",
       "3686               4            0       0               4              -1  \n",
       "3687               2            0       1               2              -1  \n",
       "3688               2            0       0               3              -1  \n",
       "3689               3            1       0               3              -4  \n",
       "3690               1            1       0               2              -1  \n",
       "\n",
       "[3691 rows x 29401 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training predictors\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#for i in range(len(text_data.lemmatized_comment)):\n",
    "    #text_data.review[i] = lemmatizer.lemmatize(text_data.lemmatized_comment[i])\n",
    "text=text_data.lemmatized_comment.values.astype('U')\n",
    "vect_11 = CountVectorizer(ngram_range=(2, 2))\n",
    "BOW_feature = pd.DataFrame(vect_11.fit_transform(text).toarray())\n",
    "Y = full_data.task\n",
    "\n",
    "frames = [BOW_feature,numerical_data]\n",
    "X = pd.concat(frames,axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "07c9d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.108\n",
      "Recall: 0.286\n",
      "F1: 0.157\n",
      "Accuracy: 0.690\n"
     ]
    }
   ],
   "source": [
    "X_train_PD, X_test_PD, y_train_PD, y_test_PD = train_test_split(X, Y_PD, random_state=0, train_size = .70)\n",
    "\n",
    "# Build the model\n",
    "# Classifier for PD\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "NB_PD = GaussianNB()\n",
    "NB_PD.fit(X_train_PD,y_train_PD)\n",
    "NB_predict_test_PD = NB_PD.predict(X_test_PD)\n",
    "get_performance(NB_predict_test_PD,y_test_PD,'PD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b72bdb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.756\n",
      "Recall: 0.710\n",
      "F1: 0.733\n",
      "Accuracy: 0.665\n"
     ]
    }
   ],
   "source": [
    "# Classifier for RT\n",
    "X_train_RT, X_test_RT, y_train_RT, y_test_RT = train_test_split(X, Y_RT, random_state=0, train_size = .70)\n",
    "NB_RT = GaussianNB()\n",
    "NB_RT.fit(X_train_RT,y_train_RT)\n",
    "NB_predict_test_RT = NB_RT.predict(X_test_RT)\n",
    "get_performance(NB_predict_test_RT,y_test_RT,'RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "991e55fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.053\n",
      "Recall: 0.155\n",
      "F1: 0.079\n",
      "Accuracy: 0.727\n"
     ]
    }
   ],
   "source": [
    "# Classifier for FR\n",
    "X_train_FR, X_test_FR, y_train_FR, y_test_FR = train_test_split(X, Y_FR, random_state=0, train_size = .70)\n",
    "NB_FR = GaussianNB()\n",
    "NB_FR.fit(X_train_FR,y_train_FR)\n",
    "NB_predict_test_FR = NB_FR.predict(X_test_FR)\n",
    "get_performance(NB_predict_test_FR,y_test_FR,'FR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ec2c24d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.087\n",
      "Recall: 0.188\n",
      "F1: 0.119\n",
      "Accuracy: 0.505\n"
     ]
    }
   ],
   "source": [
    "# Classifier for UE\n",
    "X_train_UE, X_test_UE, y_train_UE, y_test_UE = train_test_split(X, Y_UE, random_state=0, train_size = .70)\n",
    "NB_UE = GaussianNB()\n",
    "NB_UE.fit(X_train_UE,y_train_UE)\n",
    "NB_predict_test_UE = NB_UE.predict(X_test_UE)\n",
    "get_performance(NB_predict_test_UE,y_test_UE,'UE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb8511",
   "metadata": {},
   "source": [
    "Medium stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0ef0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_stopwords = []\n",
    "with open(\"medium.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ef55bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "medium_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in medium_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb8bdc",
   "metadata": {},
   "source": [
    "Large stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e5338f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_stopwords = []\n",
    "with open(\"large_stopwords.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "large_stopwords = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "993a0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in large_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c453790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7257"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba1faf",
   "metadata": {},
   "source": [
    "small stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "172971f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_stopwords = []\n",
    "with open(\"small.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "small_stopwords = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30249c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in small_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "496b7a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7734"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5f190a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_stopwords = []\n",
    "with open(\"very_small.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "smallest_stopwords = lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a795a1d5",
   "metadata": {},
   "source": [
    "very small stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6a2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_stopwords = []\n",
    "with open(\"very_small.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "smallest_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in smallest_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebc32475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7849"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3161d7",
   "metadata": {},
   "source": [
    "technology domain stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "618990f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_stopwords = []\n",
    "with open(\"technology_domain_stopwords.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "technology_stopwords = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6e54b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_stopwords = []\n",
    "with open(\"technology_domain_stopwords.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "technology_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in technology_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5b662f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7823"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c25ef",
   "metadata": {},
   "source": [
    "Naive approach stackover flow approach for stackoverflow stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a425642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_stopwords = []\n",
    "with open(\"naive_approach.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "naive_stopwords = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c04a840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_stopwords = []\n",
    "with open(\"naive_approach.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "naive_stopwords = lines\n",
    "processed_txt = ''\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in naive_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "62de2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7774"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a4649",
   "metadata": {},
   "source": [
    "TFIDF approach for stackoverflow stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1702b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_stopwords = []\n",
    "with open(\"tfidf_approach.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "tfidf_stopwords = lines\n",
    "processed_txt = ''\n",
    "txt = []\n",
    "for i in range(len(text_data)):\n",
    "    text = text_data.review[i]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "    text = text.split()\n",
    "    text_processed = [lemmatizer.lemmatize(word) for word in text if word not in tfidf_stopwords]\n",
    "    text_processed = ' '.join(text_processed)\n",
    "    txt.append(text_processed)\n",
    "    processed_txt = processed_txt + text_processed + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aafb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2b79386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7779"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0a5e9",
   "metadata": {},
   "source": [
    "BOW feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b16952f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_11 = CountVectorizer(ngram_range=(2, 2))\n",
    "BOW_feature = pd.DataFrame(vect_11.fit_transform(txt).toarray())\n",
    "Y = full_data.task\n",
    "\n",
    "frames = [BOW_feature,numerical_data]\n",
    "X = pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "65415ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25770</th>\n",
       "      <th>25771</th>\n",
       "      <th>25772</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "      <th>future</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3691 rows × 25780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  25770  25771  25772  rating  past  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       1     1   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     5   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...     ...   ...   \n",
       "3686  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     3   \n",
       "3687  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3688  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       3     0   \n",
       "3689  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "3690  0  0  0  0  0  0  0  0  0  0  ...      0      0      0       5     0   \n",
       "\n",
       "      present_simple  present_con  future  sentiScore_pos  sentiScore_neg  \n",
       "0                  2            1       0               3              -1  \n",
       "1                  9            0       0               3              -1  \n",
       "2                  1            1       0               2              -1  \n",
       "3                  4            1       0               3              -1  \n",
       "4                 14            2       0               4              -4  \n",
       "...              ...          ...     ...             ...             ...  \n",
       "3686               4            0       0               4              -1  \n",
       "3687               2            0       1               2              -1  \n",
       "3688               2            0       0               3              -1  \n",
       "3689               3            1       0               3              -4  \n",
       "3690               1            1       0               2              -1  \n",
       "\n",
       "[3691 rows x 25780 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1e68b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.111\n",
      "Recall: 0.420\n",
      "F1: 0.175\n",
      "Accuracy: 0.601\n"
     ]
    }
   ],
   "source": [
    "X_train_PD, X_test_PD, y_train_PD, y_test_PD = train_test_split(X, Y_PD, random_state=0, train_size = .70)\n",
    "\n",
    "# Build the model\n",
    "# Classifier for PD\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "NB_PD = GaussianNB()\n",
    "NB_PD.fit(X_train_PD,y_train_PD)\n",
    "NB_predict_test_PD = NB_PD.predict(X_test_PD)\n",
    "get_performance(NB_predict_test_PD,y_test_PD,'PD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6350237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.722\n",
      "Recall: 0.782\n",
      "F1: 0.751\n",
      "Accuracy: 0.665\n"
     ]
    }
   ],
   "source": [
    "# Classifier for RT\n",
    "X_train_RT, X_test_RT, y_train_RT, y_test_RT = train_test_split(X, Y_RT, random_state=0, train_size = .70)\n",
    "NB_RT = GaussianNB()\n",
    "NB_RT.fit(X_train_RT,y_train_RT)\n",
    "NB_predict_test_RT = NB_RT.predict(X_test_RT)\n",
    "get_performance(NB_predict_test_RT,y_test_RT,'RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c5a641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.079\n",
      "Recall: 0.333\n",
      "F1: 0.128\n",
      "Accuracy: 0.656\n"
     ]
    }
   ],
   "source": [
    "# Classifier for FR\n",
    "X_train_FR, X_test_FR, y_train_FR, y_test_FR = train_test_split(X, Y_FR, random_state=0, train_size = .70)\n",
    "NB_FR = GaussianNB()\n",
    "NB_FR.fit(X_train_FR,y_train_FR)\n",
    "NB_predict_test_FR = NB_FR.predict(X_test_FR)\n",
    "get_performance(NB_predict_test_FR,y_test_FR,'FR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8074cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/fanyaohou/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.117\n",
      "Recall: 0.325\n",
      "F1: 0.172\n",
      "Accuracy: 0.443\n"
     ]
    }
   ],
   "source": [
    "# Classifier for UE\n",
    "X_train_UE, X_test_UE, y_train_UE, y_test_UE = train_test_split(X, Y_UE, random_state=0, train_size = .70)\n",
    "NB_UE = GaussianNB()\n",
    "NB_UE.fit(X_train_UE,y_train_UE)\n",
    "NB_predict_test_UE = NB_UE.predict(X_test_UE)\n",
    "get_performance(NB_predict_test_UE,y_test_UE,'UE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf02640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1298"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3ad02e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ''\n",
    "with open('queries.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        q = q + line + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87579376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I insert an element in array at a given position?\\n \\n How do I compress or zip a directory recursively?\\n \\n How do I decompress a GZip file in Java?\\n \\n How do I compress a file in GZip format?\\n \\n How do I use PriorityBlockingQueue class?\\n \\n How do I parse a text string into date and time?\\n \\n How documents are represented in MongoDB Java Driver?\\n \\n How do I connect to a MongoDB Database?\\n \\n How do I send an HTML email?\\n \\n How do I read last n characters from a file?\\n \\n Creating MySql database programatically in Java\\n \\n Generating MD5 digest from File or InputStream object\\n \\n How do I calculate the MD5 digest of a string?\\n \\n How do I clone an array variable?\\n \\n How to implement the hashCode and equals method using Apache Commons?\\n \\n How to establish connection to database with Properties?\\n \\n How to monitor file or directory changes?\\n \\n How do I move a file in JDK 7?\\n \\n How do I create and delete a file in JDK 7?\\n \\n How to recursively list all text files in a directory?\\n \\n How to verify digital signature of a signed data?\\n \\n How to create a digital signature and sign data?\\n \\n How do I generate public and private keys?\\n \\n How do I copy a file in JDK 7?\\n \\n How do I set the value of file attributes?\\n \\n How do I set file last modified time? \\n \\n How do I reverse the order of array elements?\\n \\n How do I send an Http Post request?\\n \\n How do I get Http response body as a string?\\n \\n How do I get entity ContentType in HttpClient?\\n \\n How do I execute Http Get request?\\n \\n How do I get the primary key of any JPA entity?\\n \\n How do I delete entity object in JPA?\\n \\n How do I get all available currency codes?\\n \\n How do I get host default timezone id?\\n \\n How to create an XML file of a POJO using JAXB?\\n \\n How do I compare two dates?\\n \\n How do I change date formatting symbols?\\n \\n How do I retrieve available schemas in database?\\n \\n How do I call a stored procedure that return a result set?\\n \\n How do I convert raw IP address to String?\\n \\n How do I create port scanner program?\\n \\n How do I get MAC address of a host?\\n \\n How do I create a client-server socket communication?\\n \\n How do I read download webpage content?\\n \\n How do I get IP address of localhost?\\n \\n How do I get cryptographic security providers?\\n \\n How do I create an encrypted string for password?\\n \\n How do I breaks a paragraph into sentences?\\n \\n How do I change the date format symbols for a specified locale?\\n \\n How do I change number format symbols?\\n \\n How do I parse a number for a locale?\\n \\n How do I iterate a subset of a string?\\n \\n How do I get attributes of element during SAX parsing?\\n \\n How do I get JDBC driver property information?\\n \\n How do I get numeric functions supported by database?\\n \\n How do I get data types supported by database?\\n \\n How do I execute stored procedure?\\n \\n How do I print a file using the default registered application?\\n \\n How do I turn the Num Lock button on?\\n \\n How do I create subscript in iText?\\n \\n How do I delete file from FTP server?\\n \\n How do I get list of files from FTP server?\\n \\n How do I upload file to FTP server?\\n \\n How do I create an Excel document using Apache POI?\\n \\n Draw a draggable triangle in Java\\n \\n Take a screenshot and save as image in Java\\n \\n Load a Resource Bundle \\n \\n Instantiate unknown class at runtime and call the object methods\\n \\n Invoke methods of an object using reflection\\n \\n List methods of a class using Reflection \\n \\n Redirect Servlet Call to Another URL\\n \\n Get and Set Session Variables in a Servlet\\n \\n Get Request Parameters in a Servlet \\n \\n Connect to a database and read from table \\n \\n creating in-memory lucene index\\n \\n building lucene search query\\n \\n doing lucene search\\n \\n read JSON data to JSON Object Model\\n \\n how to serialize JSON Object \\n \\n execute the test cases using Test runner\\n \\n Java Compare file content\\n \\n Java Add comment in XML\\n \\n XML How to Add CDATA data \\n \\n How to Create a Shared File Lock on a File\\n \\n How to Tokenize Java Source Code\\n \\n How to Visit All the Elements in a DOM Document\\n \\n XML How to Remove all attributes\\n \\n XML How to Fetch data from the Web\\n \\n How to Render HTML and save to Image\\n \\n How to Move image on screen\\n \\n How to Load font from ttf file\\n \\n How to create a server socket\\n \\n How to Sort a Map by values\\n \\n How to Store properties as XML file\\n \\n Passing Parameters from Java Code to Scripts\\n \\n How to Create thumbnail views of images\\n \\n How to Capture image from webcam in java\\n \\n Java Graphics How to Rotate Shape\\n \\n How to Load an image and write text to it\\n \\n Parsing an XML File Using SAX\\n \\n How to add attribute to an element\\n \\n How to add text node to an element\\n \\n How to create comments node for XML\\n \\n How to change a specific element using XPath\\n \\n How to use a StAX parser\\n \\n How to serialize JSON Object\\n \\n Read JSON Array\\n \\n How to search for HTML XML comments\\n \\n How to use hashmap properties with JAXB\\n \\n How do I create a web based file upload?\\n \\n How to shear Shape?\\n \\n How to transform ellipse\\n \\n How to write text onto image\\n \\n How to change text color with CSS for Label?\\n \\n How to draw text content to Image?\\n \\n Java Mail POP3 Client\\n \\n Java Mail Secure POP3 Client\\n \\n Get Email Header\\n \\n Add Extra Page To Existing PDF\\n \\n Simple Annotations with Another PDF document\\n \\n Adding AWT Image to PDF with Color\\n \\n Adding Paragraph to a PDF Page\\n \\n Add Watermark Image to an Existing PDF File\\n \\n Adding Bookmarks for PDF document\\n \\n Copy and paste data with the clipboard\\n \\n Connect with a Web server\\n \\n Connects to an rshell daemon\\n \\n Connects to an rlogin daemon\\n \\n POSTing data to an HTTP server\\n \\n Get session from request\\n \\n Adding Drop Shadow to a Shape\\n \\n Uses serialization to perform deep copy cloning.\\n \\n Execute Javascript script in a file\\n \\n Listing All Script Engines\\n \\n Pass parameter to JavaScript through Java code\\n \\n Using Java Objects in JavaScript\\n \\n Read and execute a script source file\\n \\n Use DSA key pair to generate XML Signature\\n \\n Determining operating system support for attribute views\\n \\n Change label border with CSS (Smart GWT)\\n \\n Servlet: Session bind listener\\n \\n Basic Authentication For JSP Page\\n \\n Checking Read Write Permission for a Directory\\n \\n Listing All Permissions Granted to a Loaded Class\\n \\n Generate a DSA signature\\n \\n Signing a Java Object\\n \\n Generating a Message Authentication Code (MAC)\\n \\n Execute a command from code\\n \\n Simulate a mouse click\\n \\n Extract First File From Zip File Example\\n \\n Extract File With CRC32 Checksum\\n \\n Extract Zip File With Adler32 Checksum\\n \\n Load New HTML File Using Applet Context\\n \\n Set orientation for print job\\n \\n Determine format of an image\\n \\n Compress a JPEG file\\n \\n Get Midi audio file properties\\n \\n Play Midi audio\\n \\n List available cryptographic services\\n \\n Get bytes of generated symmetric key\\n \\n Import package in script\\n \\n Get script engine details\\n \\n Send notification at MBean attribute change\\n \\n JavaFX Creating a Sprite Animation\\n \\n Using a memory mapped file for a huge matrix\\n \\n github api access example java\\n \\n How to write an Object to file in Java\\n \\n Send HTTP requests for serialized objects\\n \\n RichText editor component for SWT based applications\\n \\n Parsing JavaScript code using Mozilla Rhino\\n \\n DOM Parsing in Java\\n \\n A block of text to use as input to the regular expression matcher\\n \\n How to get HTTP Response Header in Java\\n \\n Convert Object to XML\\n '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f389045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text = q\n",
    "text = text.lower()\n",
    "text = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\",text)\n",
    "text = text.split()\n",
    "text_processed = [lemmatizer.lemmatize(word) for word in text]\n",
    "text_processed = ' '.join(text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cb09f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text_processed.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c8651549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "#medium_stopwords = lines\n",
    "t = text_processed.split()\n",
    "t_t = [lemmatizer.lemmatize(word) for word in t if word not in tfidf_stopwords]\n",
    "t_t = ' '.join(t_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dfaae298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(t_t.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01008852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
